{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiH6PmNWnKOU",
        "outputId": "5574370c-e7fe-4c29-8a3d-ba6a377778ad"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import bfloat16\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    pipeline,\n",
        "    GenerationConfig,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from rich import print as rprint\n",
        "from rich.panel import Panel\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JObqP13JnKOX",
        "outputId": "6be6a523-e049-4ebe-d230-dd3387f62755"
      },
      "outputs": [],
      "source": [
        "device = 'cpu'\n",
        "if(torch.cuda.is_available()):\n",
        "    device = 'cuda'\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0sam-l3nKOb",
        "outputId": "c261f032-4add-4b7f-d026-eac17724d7fb"
      },
      "outputs": [],
      "source": [
        "loader = TextLoader(\"/Pytorch_Codes/BD Police.txt\", encoding=\"utf8\")\n",
        "texts = loader.load()\n",
        "\n",
        "character_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
        "texts = character_splitter.split_documents(texts)\n",
        "\n",
        "print(f\"Number of chunks: {len(texts)}\")\n",
        "print(\"Document created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI-ODw-JnKOc",
        "outputId": "f74c426d-91ef-478e-9597-7452f016c1d4"
      },
      "outputs": [],
      "source": [
        "documents = [doc.page_content for doc in texts]\n",
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRbcqesLnKOd",
        "outputId": "b0678a9d-f8ef-4385-fc95-4b3fe5369ffe"
      },
      "outputs": [],
      "source": [
        "model_kwargs = {\"device\": device}\n",
        "embed_model_id = \"BAAI/bge-m3\"\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embed_model_id, model_kwargs = model_kwargs)\n",
        "print(f\"Embedding Model: {embed_model_id} has been loaded!\")\n",
        "\n",
        "db = Chroma.from_texts(texts=documents, embedding=embeddings, persist_directory=\"chroma_db\")\n",
        "print(\"Chroma database updated successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0RVoJyynKOf"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"[INST]\n",
        "<>\n",
        "You are a helpful Bangla AI assistant.\n",
        "\n",
        "Use the following pieces of 'context' to answer the user's questions. Only Respond in Bangla.\n",
        "\n",
        "Context:\n",
        "    {context}\n",
        "\n",
        "Question: {question}[/INST]\n",
        "Helpful Answer (in Bangla):\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate(\n",
        "    input_variables=[\"question\", \"context\"],\n",
        "    output_parser=None,\n",
        "    partial_variables={},\n",
        "    messages=[\n",
        "        HumanMessagePromptTemplate(\n",
        "            prompt=PromptTemplate(\n",
        "                input_variables=[\"question\", \"context\"],\n",
        "                output_parser=None,\n",
        "                partial_variables={},\n",
        "                template=template,\n",
        "                template_format=\"f-string\",\n",
        "                validate_template=True,\n",
        "            ),\n",
        "            additional_kwargs={},\n",
        "        )\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La1LZpAmnKOg"
      },
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWn0DtcOnKOh"
      },
      "outputs": [],
      "source": [
        "\n",
        "api_key = \"\"  # Groq API Key\n",
        "groq_chat = ChatGroq(\n",
        "            groq_api_key=api_key,\n",
        "            model_name='llama-3.1-8b-instant'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJx337shnKOi",
        "outputId": "28c0caf9-038e-4759-ab58-7b4ffb59a4c9"
      },
      "outputs": [],
      "source": [
        "rag_chain_from_docs = (\n",
        "    RunnablePassthrough.assign(\n",
        "        context=lambda x: format_docs(x[\"context\"])\n",
        "    )\n",
        "    | prompt_template\n",
        "    | groq_chat\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 4, \"fetch_k\": 10})\n",
        "\n",
        "print(\"Retreiver initialized successfully!\")\n",
        "\n",
        "rag_chain_with_source = RunnableParallel(\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        ").assign(answer=rag_chain_from_docs)\n",
        "\n",
        "chain = rag_chain_with_source\n",
        "print(\"RAG chain created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wvf7GdmQnKOj",
        "outputId": "b513e6b0-3ba6-4211-e9c7-913afb810a89"
      },
      "outputs": [],
      "source": [
        "query = \"অন্যান্য সংস্থা ও প্রতিষ্ঠানের সঙ্গে সমন্বয় কিভাবে করা হবে?\"\n",
        "response = chain.invoke(query)\n",
        "response_start = response[\"answer\"].find(\"### Response:\") + len(\n",
        "    \"### Response:\"\n",
        ")\n",
        "\n",
        "final_answer = response[\"answer\"][response_start:].strip()\n",
        "\n",
        "if isinstance(final_answer, str) and \"Helpful Answer\" in final_answer:\n",
        "    cleaned_answer = final_answer.split(\"Helpful Answer (in Bangla):\", 1)[-1].strip()\n",
        "else:\n",
        "    cleaned_answer = final_answer\n",
        "\n",
        "print(f\"উত্তর: {cleaned_answer}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "new_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
